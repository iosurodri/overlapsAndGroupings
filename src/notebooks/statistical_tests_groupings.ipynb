{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the libraries to be used in the experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import f_oneway, ttest_ind, shapiro\n",
    "import scipy.stats as ss\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue loading the data of the populations to be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "6 columns passed, passed data had 11 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             raise AssertionError(\n\u001b[0m\u001b[1;32m    693\u001b[0m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 6 columns passed, passed data had 11 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5e8714c00417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdata_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_arch2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_arch2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 6 columns passed, passed data had 11 columns"
     ]
    }
   ],
   "source": [
    "data_arch2 = [\n",
    "    ['max', 0.8658, 0.8682, 0.8606, 0.8632, 0.8578],\n",
    "    ['avg', 0.8584, 0.8661, 0.8602, 0.8633, 0.8643],\n",
    "    ['g_prod', 0.8750, 0.8714, 0.8735, 0.8738, 0.8711, 0.8753, 0.8744, 0.8727, 0.8798, 0.8789],\n",
    "    ['g_ob', 0.8735, 0.8798, 0.8739, 0.8736, 0.8697, 0.872, 0.8813, 0.8758, 0.8719, 0.8762],\n",
    "    ['gp_prod_p_0_1', 0.8773, 0.8798, 0.8802, 0.8814, 0.8819],\n",
    "    ['gp_prod_p_0_25', 0.8796, 0.8838, 0.8825, 0.882, 0.8784, 0.8819, 0.8821, 0.8796, 0.8828, 0.8763],\n",
    "    ['gp_prod_p_0_5', 0.8723, 0.8794, 0.8783, 0.8829, 0.8755],\n",
    "    ['gp_comb_maxAndOB', 0.873, 0.8719, 0.8682, 0.8691, 0.8698, 0.8697, 0.8697, 0.8742, 0.8682, 0.8768],\n",
    "    ['gp_comb_maxAndProd', 0.8821, 0.8716, 0.8789, 0.8779, 0.8716, 0.8781, 0.8688, 0.8732, 0.873, 0.8717],\n",
    "    ['gp_comb_maxProdAndOB', 0.8713, 0.8762, 0.8766, 0.8744, 0.8713, 0.8714, 0.8734, 0.8739, 0.8755, 0.876],\n",
    "    ['gp_comb_prodAndOB', 0.8746, 0.8799, 0.8766, 0.8766, 0.8797, 0.873, 0.8685, 0.8741, 0.873, 0.8715],\n",
    "    ['gp_comp_max_prodAndOB', 0.88, 0.8735, 0.872, 0.8729, 0.8782, 0.8735, 0.8784, 0.8783, 0.8798, 0.8772],\n",
    "    ['gp_comp_ob_maxandProd', 0.8732, 0.877, 0.8754, 0.8728, 0.8741, 0.8782, 0.8693, 0.8761, 0.8735, 0.8773],\n",
    "    ['gp_comp_prod_maxAndOB', 0.8733, 0.8785, 0.8762, 0.8698, 0.8754, 0.8717, 0.8747, 0.8675, 0.8652, 0.8767],\n",
    "    ['gp_comp_prod_maxAndProd', 0.8747, 0.8779, 0.8774, 0.875, 0.8728, 0.8753, 0.8762, 0.8759, 0.8788, 0.8764],\n",
    "    ['gp_comp_prod_prodAndOB', 0.8741, 0.874, 0.879, 0.8756, 0.8749, 0.8695, 0.8763, 0.876, 0.8802, 0.8756]\n",
    "]\n",
    "\n",
    "data_values = [values[1:] for values in data_arch2]\n",
    "df = pd.DataFrame(data=data_arch2, columns=['Model', 'Test1', 'Test2', 'Test3', 'Test4', 'Test5'])\n",
    "df = df.set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by testing for normality in each population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro test result for grouping max: ShapiroResult(statistic=0.9860615730285645, pvalue=0.9641755223274231)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping avg: ShapiroResult(statistic=0.9580554366111755, pvalue=0.7943816781044006)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping g_prod: ShapiroResult(statistic=0.9100196361541748, pvalue=0.4677083194255829)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping g_ob: ShapiroResult(statistic=0.8831984996795654, pvalue=0.32405728101730347)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_prod_p_0_1: ShapiroResult(statistic=0.9215002059936523, pvalue=0.539663553237915)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_prod_p_0_25: ShapiroResult(statistic=0.9447110891342163, pvalue=0.6994076371192932)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_prod_p_0_5: ShapiroResult(statistic=0.992158055305481, pvalue=0.9866788983345032)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comb_maxAndOB: ShapiroResult(statistic=0.9400262832641602, pvalue=0.6661241054534912)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comb_maxAndProd: ShapiroResult(statistic=0.8774616122245789, pvalue=0.2979663014411926)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comb_maxProdAndOB: ShapiroResult(statistic=0.8407771587371826, pvalue=0.1670815348625183)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comb_prodAndOB: ShapiroResult(statistic=0.8842251896858215, pvalue=0.32889795303344727)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comp_max_prodAndOB: ShapiroResult(statistic=0.8635283708572388, pvalue=0.24119557440280914)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comp_ob_maxandProd: ShapiroResult(statistic=0.9355018138885498, pvalue=0.6343367695808411)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comp_prod_maxAndOB: ShapiroResult(statistic=0.9742259383201599, pvalue=0.9016179442405701)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comp_prod_maxAndProd: ShapiroResult(statistic=0.9315709471702576, pvalue=0.6071218252182007)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n",
      "Shapiro test result for grouping gp_comp_prod_prodAndOB: ShapiroResult(statistic=0.8070403933525085, pvalue=0.09236515313386917)\n",
      "We cannot discard that the previous population was sampled from a normal distribution\n"
     ]
    }
   ],
   "source": [
    "for pop in data_arch2:\n",
    "    test_result = ss.shapiro(pop[1:])\n",
    "    print('Shapiro test result for grouping {}: {}'.format(pop[0], test_result))\n",
    "    if (test_result[1] > 0.05):\n",
    "        print('We cannot discard that the previous population was sampled from a normal distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All populations seem to be normal, so we apply statistical tests that allow for normality. We now will perform ANOVA testing in all populations to check if there are statistical differences among them:\n",
    "\n",
    "<font color='red'>Warning</font>: Populations are very small (n = 5, n < 20), so populations may not really be normal. Further experimenting could be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_onewayResult(statistic=15.118081078231254, pvalue=1.280219145791561e-15)\n"
     ]
    }
   ],
   "source": [
    "test_result = ss.f_oneway(*data_values, axis=0)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value obtained is well beyond the imposed threshold of 0.05, so we can safely discard the null hypothesis that all populations are equal (and thus, there must be some model whose accuracies are statistically better or worse than those of the rest). \n",
    "\n",
    "We now need to find out which models are statistically different via post-hoc tests between each pair of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n",
      "/home/iosu.rodriguez/anaconda3/envs/pytorch/lib/python3.8/site-packages/scikit_posthocs/_posthocs.py:1269: UserWarning: p-value capped: true value larger than 0.25\n",
      "  vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]], midrank=midrank)[2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.102649</td>\n",
       "      <td>0.037320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.056741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.177706</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.043801</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.010368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121731</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.062981</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.010368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.225078</td>\n",
       "      <td>0.121731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.102219</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.121731</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.004356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.177706</td>\n",
       "      <td>0.062981</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137062</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.132286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.172738</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.102219</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>0.137062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025232</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.245070</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.025232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.138963</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.138963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.043801</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.121731</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.132286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.138963</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.102649</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.172738</td>\n",
       "      <td>0.245070</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>0.056741</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.138963</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7   \\\n",
       "1   1.000000  0.250000  0.004356  0.004356  0.004356  0.004356  0.004356   \n",
       "2   0.250000  1.000000  0.004356  0.004356  0.004356  0.004356  0.004356   \n",
       "3   0.004356  0.004356  1.000000  0.250000  0.004356  0.004356  0.037320   \n",
       "4   0.004356  0.004356  0.250000  1.000000  0.013420  0.021065  0.250000   \n",
       "5   0.004356  0.004356  0.004356  0.013420  1.000000  0.250000  0.225078   \n",
       "6   0.004356  0.004356  0.004356  0.021065  0.250000  1.000000  0.121731   \n",
       "7   0.004356  0.004356  0.037320  0.250000  0.225078  0.121731  1.000000   \n",
       "8   0.005658  0.004356  0.070584  0.037320  0.004356  0.004356  0.010368   \n",
       "9   0.003572  0.003572  0.173200  0.250000  0.177706  0.062981  0.250000   \n",
       "10  0.003572  0.003572  0.250000  0.250000  0.003571  0.003571  0.102219   \n",
       "11  0.003715  0.003715  0.008781  0.054596  0.037278  0.059879  0.250000   \n",
       "12  0.004356  0.004356  0.250000  0.250000  0.043801  0.021065  0.250000   \n",
       "13  0.004356  0.004356  0.250000  0.250000  0.004356  0.004356  0.121731   \n",
       "14  0.004356  0.004356  0.250000  0.250000  0.010368  0.010368  0.250000   \n",
       "15  0.004356  0.004356  0.102649  0.250000  0.021065  0.004356  0.200097   \n",
       "16  0.004356  0.004356  0.037320  0.056741  0.010368  0.010368  0.250000   \n",
       "\n",
       "          8         9         10        11        12        13        14  \\\n",
       "1   0.005658  0.003572  0.003572  0.003715  0.004356  0.004356  0.004356   \n",
       "2   0.004356  0.003572  0.003572  0.003715  0.004356  0.004356  0.004356   \n",
       "3   0.070584  0.173200  0.250000  0.008781  0.250000  0.250000  0.250000   \n",
       "4   0.037320  0.250000  0.250000  0.054596  0.250000  0.250000  0.250000   \n",
       "5   0.004356  0.177706  0.003571  0.037278  0.043801  0.004356  0.010368   \n",
       "6   0.004356  0.062981  0.003571  0.059879  0.021065  0.004356  0.010368   \n",
       "7   0.010368  0.250000  0.102219  0.250000  0.250000  0.121731  0.250000   \n",
       "8   1.000000  0.069525  0.069525  0.003715  0.021065  0.010368  0.026977   \n",
       "9   0.069525  1.000000  0.137062  0.250000  0.250000  0.132286  0.250000   \n",
       "10  0.069525  0.137062  1.000000  0.025232  0.250000  0.250000  0.250000   \n",
       "11  0.003715  0.250000  0.025232  1.000000  0.250000  0.076000  0.138963   \n",
       "12  0.021065  0.250000  0.250000  0.250000  1.000000  0.250000  0.250000   \n",
       "13  0.010368  0.132286  0.250000  0.076000  0.250000  1.000000  0.250000   \n",
       "14  0.026977  0.250000  0.250000  0.138963  0.250000  0.250000  1.000000   \n",
       "15  0.010368  0.172738  0.245070  0.250000  0.250000  0.250000  0.250000   \n",
       "16  0.004356  0.250000  0.250000  0.138963  0.250000  0.250000  0.250000   \n",
       "\n",
       "          15        16  \n",
       "1   0.004356  0.004356  \n",
       "2   0.004356  0.004356  \n",
       "3   0.102649  0.037320  \n",
       "4   0.250000  0.056741  \n",
       "5   0.021065  0.010368  \n",
       "6   0.004356  0.010368  \n",
       "7   0.200097  0.250000  \n",
       "8   0.010368  0.004356  \n",
       "9   0.172738  0.250000  \n",
       "10  0.245070  0.250000  \n",
       "11  0.250000  0.138963  \n",
       "12  0.250000  0.250000  \n",
       "13  0.250000  0.250000  \n",
       "14  0.250000  0.250000  \n",
       "15  1.000000  0.250000  \n",
       "16  0.250000  1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values_np = np.array(data_values)\n",
    "sp.posthoc_anderson(data_values_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1    2    3    4    5    6    7    8    9    10   11   12   13   14   15  \\\n",
      "1  -1.0  0.0  3.0  2.0  1.0  1.0  1.0  0.0  1.0  2.0  1.0  1.0  1.0  1.0  1.0   \n",
      "2   0.0 -1.0  3.0  2.0  1.0  1.0  1.0  0.0  1.0  2.0  1.0  1.0  1.0  1.0  1.0   \n",
      "3   3.0  3.0 -1.0  0.0  1.0  1.0  2.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0   \n",
      "4   2.0  2.0  0.0 -1.0  2.0  1.0  0.0  3.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0   \n",
      "5   1.0  1.0  1.0  2.0 -1.0  0.0  0.0  1.0  3.0  1.0  0.0  2.0  2.0  2.0  3.0   \n",
      "6   1.0  1.0  1.0  1.0  0.0 -1.0  0.0  1.0  3.0  1.0  0.0  2.0  1.0  2.0  2.0   \n",
      "7   1.0  1.0  2.0  0.0  0.0  0.0 -1.0  1.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8   0.0  0.0  0.0  3.0  1.0  1.0  1.0 -1.0  2.0  0.0  1.0  2.0  3.0  3.0  2.0   \n",
      "9   1.0  1.0  0.0  0.0  3.0  3.0  0.0  2.0 -1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "10  2.0  2.0  0.0  0.0  1.0  1.0  3.0  0.0  0.0 -1.0  3.0  0.0  0.0  0.0  0.0   \n",
      "11  1.0  1.0  2.0  3.0  0.0  0.0  0.0  1.0  0.0  3.0 -1.0  0.0  0.0  0.0  0.0   \n",
      "12  1.0  1.0  0.0  0.0  2.0  2.0  0.0  2.0  0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "13  1.0  1.0  0.0  0.0  2.0  1.0  0.0  3.0  0.0  0.0  0.0  0.0 -1.0  0.0  0.0   \n",
      "14  1.0  1.0  0.0  0.0  2.0  2.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0 -1.0  0.0   \n",
      "15  1.0  1.0  0.0  0.0  3.0  2.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0   \n",
      "16  1.0  1.0  0.0  0.0  3.0  2.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "     16  \n",
      "1   1.0  \n",
      "2   1.0  \n",
      "3   0.0  \n",
      "4   0.0  \n",
      "5   3.0  \n",
      "6   2.0  \n",
      "7   0.0  \n",
      "8   2.0  \n",
      "9   0.0  \n",
      "10  0.0  \n",
      "11  0.0  \n",
      "12  0.0  \n",
      "13  0.0  \n",
      "14  0.0  \n",
      "15  0.0  \n",
      "16 -1.0  \n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<AxesSubplot:>, <matplotlib.colorbar.ColorbarBase at 0x7f97d0913610>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pc = sp.posthoc_conover(data_values_np)\n",
    "cmap = ['#FFFFFF', \"#F03828\", '#005A2E', '#1D8C43', '#A2DA9C']\n",
    "heatmap_args = {'cmap': cmap, 'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True, 'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\n",
    "# heatmap_args = {'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True, 'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\n",
    "sp.sign_plot(pc, **heatmap_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50b926a050cc029ac752863e4f86b7e2171f26cfdc0be8c315e356fc3ef03bad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
